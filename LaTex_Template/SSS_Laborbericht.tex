%---------------
%╔═╗╔═╗╔╦╗╦  ╦╔═╗
%╚═╗║╣    ║  ║  ║╠═╝
%╚═╝╚═╝  ╩  ╚═╝╩  
%---------------

% language setup
\newcommand{\docLanguage}{ngerman}
%\newcommand{\docLanguage}{english}

% DOCUMENT SETUP
\documentclass[12pt, oneside, a4paper, \docLanguage]{report}
\usepackage[left=3cm, 
			right=2.5cm, 
			top=2.5cm, 
			bottom=2.5cm, 
			includehead, 
			includefoot]{geometry}

% line spacing
\usepackage{setspace}
\setstretch{1,25} % 15/12 --> 1.25

% encoding setup
% T1 font encoding for languages that use a latin alphabet
\usepackage[T1]{fontenc} 

% enhanced input encoding handling - utf8 for äÄüÜöÖß...
\usepackage[utf8]{inputenc}

%de­fines Adobe Times Ro­man as de­fault text font
\usepackage{mathptmx}
\usepackage{times} % needed for acronym package

%PDF linking package
\usepackage[hidelinks]{hyperref}


% Language Setup
\usepackage[\docLanguage]{babel}
% after babel - set chapter string
\AtBeginDocument{\renewcommand{\chaptername}{}}

% language specific bibliography style
\usepackage[numbers, square]{natbib}
%\setcitestyle{square,aysep={},yysep={;}}
\usepackage[fixlanguage]{babelbib}
\selectbiblanguage{\docLanguage}
% bliographystyle setup
% babel specific: babplain, babplai3, babalpha, babunsrt, bababbrv, bababbr3
\bibliographystyle{babunsrt}


% enumeration
\usepackage{enumitem}
% tabular extension tabularx
\usepackage{tabularx}

% math packages
\usepackage{amsmath}
\usepackage{nicefrac}
\usepackage{amsthm}
\usepackage{amsbsy}
\usepackage{amssymb}
\usepackage{amsfonts}
%\usepackage{MnSymbol}


%special characters
\usepackage{amssymb}
\usepackage{upgreek,textgreek}

% acronym package
\usepackage[printonlyused, footnote]{acronym}

% breakable text in \seqsplit{}
\usepackage{seqsplit}

% \textmu
\usepackage{textcomp}

% package provides a way to compile sections of a document using the same preamble as the main document
\usepackage{subfiles}

% driver-independent color extension - used by listings,tabularx
\usepackage[usenames,dvipsnames,table,xcdraw]{xcolor}

% -- SYNTAX HIGHLIGHTING --
\usepackage{listings}
%\input{cfgs/listings/listings_def_lang_bash-cmd.tex} % adds style BASH_CMD
%\input{cfgs/listings/listings_def_lang_bash-script.tex} % adds style BASH_SCRIPT
\input{cfgs/listings/listings_def_lang_latex.tex} % adds style LATEX
%\input{cfgs/listings/listings_def_lang_matlab.tex} % adds style MATLAB
\input{cfgs/listings/listings_def_lang_python.tex} % adds style PYTHON
%\input{cfgs/listings/listings_def_lang_c++.tex} % adds style CPP
%\input{cfgs/listings/listings_def_lang_c.tex} % adds style C
%\input{cfgs/listings/listings_def_lang_json.tex} % adds style JSON

% HEADLINE CFG
\usepackage{fancyhdr} % Headers and footers
\usepackage{lastpage}
\usepackage{ifthen}
\setlength{\headheight}{1.5cm}
%\pagestyle{fancy} % All pages have headers and footers
% override plain page style for \part, \chapter or 
% \maketitle, which implicit specifies plain page style
\input{cfgs/fancyhdr/fancyhdr_pagestyle_plain.tex}
% set list pagestyle
\input{cfgs/fancyhdr/fancyhdr_pagestyle_preface.tex}
% set default pagestyle
\input{cfgs/fancyhdr/fancyhdr_pagestyle_default_onepage.tex}
%\input{cfgs/fancyhdr/fancyhdr_pagestyle_default_twopage.tex}

\renewcommand{\chaptermark}[1]{\markright{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{#1}{}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% PICTURE CFG 
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{caption}
\usepackage[list=true,listformat=simple]{subcaption}
% floating prevention packages
\usepackage{float}    % used with [H] positioning parameter
\usepackage{placeins} % \FloatBarrier 
% tikz packages
\usepackage{tikz}
\usepackage{standalone}
\usepackage{pgfplots}


% include only specified tex files - uncommend here
\includeonly{preface/cover,
             preface/abstract,
             preface/tableofcontents,
             preface/listoffigures,
             preface/listoftables,
             preface/lstlistoflistings,
             appendix/bibliography}

%-------------------
%╔═╗╔╦╗╦═╗╦ ╔╗╔╔═╗╔═╗
%╚═╗  ║  ╠╦╝║ ║║║║ ╦ ╚═╗
%╚═╝  ╩  ╩╚═╩ ╝╚╝╚═╝╚═╝
%-------------------
\newcommand{\strLecture}{Signale, Systeme und Sensoren}
\newcommand{\strDate}{\today}
\newcommand{\strAuthorA}{Kiattipoom Pensuwan}
\newcommand{\strAuthorB}{Thanh Son Dang}
%\newcommand{\strAuthorC}{C. Author}
\newcommand{\strAuthorAEmail}{ki851pen@htwg-konstanz.de}
\newcommand{\strAuthorBEmail}{th851dan@htwg-konstanz.de}
%\newcommand{\strAuthorCEmail}{cauthor@htwg-konstanz.de}
% Versuchsbeschreibung 
\newcommand{\strTopic}{AUFBAU EINES EINFACHEN SPRACHERKENNER}
\newcommand{\strAbstract}{\qquad In diesem Versuch wird ein einfacher Spracherkenner aufgebaut, welcher nur vier einfache Befehle "Hoch", "Tief", "Rechts" und "Links" erkennen kann. Damit diese Befehle erkannt werden, müssen die Referenzspektren erstellt werden und mit den aufgenommenen akustischen Signalen verglichen. 

Um die Referenzspektren zu bekommen, muss jeder Befehl mehrmals aufgenommen, mit der Windowing-Methode zerlegen, die lokale Fouriertransformation in jedem Fenster durchführen und daraus den Mittelwert abbilden. Mit diesen Referenzspektren und der Mustererkennung durch Korrelation(Korrelationskoeffizienten nach Bravais-Pearson) können das gesprochen Wort erkannt werden.}
% hyperref customization
\hypersetup{
	pdftitle     = {\strTopic}, % title
	pdfsubject   = {\strLecture}, % subject of the document
	pdfauthor    = {\strAuthorA, \strAuthorB}, % author
	pdfkeywords  = {}, % list of keywords
	pdfcreator   = {}, % creator of the document
	pdfproducer  = {}, % producer of the document
	colorlinks   = false, % false: boxed links; true: colored links
	linkcolor    = red, % color of internal links (change box color with linkbordercolor)
    citecolor    = green, % color of links to bibliography
    filecolor    = magenta, % color of file links
    urlcolor     = cyan, % color of external links
	%bookmarks    = true, % show bookmarks bar?
	unicode	     = true, % non-Latin characters in Acrobat’s bookmarks
	pdftoolbar   = true, % show Acrobat’s toolbar?
	pdfmenubar   = true, % show Acrobat’s menu?
    pdffitwindow = false, % window fit to page when opened
	pdfnewwindow = true % links in new PDF window
}

%-----------------------------------------
% ╔╗  ╔═╗╔═╗ ╦ ╔╗╔  ╔╦╗╔═╗╔═╗╦ ╦╔╦╗╔═╗╔╗╔╔╦╗ 
% ╠╩╗║╣  ║ ╦  ║ ║║║     ║║║ ║║  ║ ║║║║║╣ ║║║ ║  
% ╚═╝╚═╝╚═╝ ╩ ╝╚╝  ═╩╝╚═╝╚═╝╚═╝╩ ╩╚═╝╝╚╝ ╩  
%-----------------------------------------

\begin{document}
\pagenumbering{Roman} 

\setcounter{section}{0}
\include{preface/cover}

\include{preface/abstract}
\clearpage

%
% TABLE OF CONTENTS
%
\include{preface/tableofcontents}

%
% Abbildungsverzeichnis
%
\include{preface/listoffigures}

%
% Tabellenverzeichnis
%
\include{preface/listoftables}



%--------------------------
% ╔═╗╦  ╦╔═╗╔═╗╔╦╗╔═╗╦═╗╔═╗ 
% ║    ╠═╣╠═╣╠═╝  ║   ║╣  ╠╦╝╚═╗ 
% ╚═╝╩  ╩╩  ╩╩      ╩   ╚═╝╩╚═╚═╝ 
%--------------------------

\pagenumbering{arabic} 
\setcounter{page}{1} 
\pagestyle{default}

%
% CHAPTER Versuch 1
%
\chapter{Fourieranalyse lang andauernder Signale}

\section{Fragestellung, Messprinzip, Aufbau, Messmittel}
\label{chap:VERSUCH_1_FRAGESTELLUNG}

\qquad Ein beliebige Spracheingabe wird über die Soundkarte mithilfe des Objektes audiorecorder aufgenommen und als akustisches Signal gespeichert.
Das originale Signal wird grafisch dargestellt. 

Dann wird dieses Signal so, dass alle Sample nahe an 0 (kleiner als 10 Prozent von Maximalen Wert) liegen, abgeschnitten(Triggerfunktion), damit alle Signale beginnen nur wenn die eigentliche Spracheingabe angefangen hat. Das neue abgeschnittene Signal sollte genau 1 s lang sein. Zur Überprüfung der Korrekheit der Triggerfunktion werden die beide grafisch dargestellten Signale verglichen.

Mithilfe der Funktion numpy.fft.fft() kann man die Fouriertransformierte des abgeschnitten Signals berechnen. Daraus wird das Amplitudenspektrum bestimmt und grafisch dargestellt.
 
Das Signal wird mit der Methode des Windowing in Abschnitte mit der Länge von 512 Samples zerlegen, die sich jeweils zur Hälfte überlappen. In jedem Fenster werden die Samples mit der Gaußschen Fensterfunktion multipliziert, die die Fensterbreite 4 Standardabweichungen hat. Dadurch werden plötzliche Sprünge vermieden.

In jedem Fenster wird eine lokale Fouriertransformation durchgeführt und daraus den Mittelwert bilden und wieder grafisch darstellen. Die Korrektheit wird durch Vergleich mit dem ohne Windowing Spektrum überprüft.


\section{Messwerte}
\label{chap:VERSUCH_1_MESSWERTE}
\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{v1.png}
	\caption{Das komplette aufgenommene Signal von den Worten "was cooles"}
\end{figure}
\section{Auswertung}
\label{chap:VERSUCH_1_AUSWERTUNG}
\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{v1_abgeschnitten.png}
	\caption{Das abgeschnittene Signal von den Worten "was cooles"}
\end{figure}

\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{Amplitudenspektrum.png}
	\caption{Das Amplitudenspektrum von dem abgeschnittenen Signal}
\end{figure}

\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{window_signal.png}
	\caption{Beispiel von einem Fenster(Blau:ohne Fensterfunktion, Orange:mit Fensterfunktion)}
\end{figure}

\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{spektrum_mittel_windowsv1.png}
	\caption{Amplitudenspektrum durch Mittelung aller lokalen Fouriertransformierten}
\end{figure}

\textit{Zusätzlich haben wir auch jede lokalen Fouriertransformierte auf einem Graph dargestellt: }

\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{spektrum_gesamter_windowsv1.png}
	\caption{Amplitudespektrum aller lokalen Fouriertransformierten}
\end{figure}


Den Code davon bitte den Anhang A.1.1 und A.1.2 sehen.

\section{Interpretation}
\label{chap:VERSUCH_1_INTERPRETATION}
Durch die Amplitudenspektren(Abbildungen 1.3, 1.5 und 1.6) kann festgestellt werden, dass die die ähnlichen Verhältnissen vorliegen aber die Amplituden variieren. Das heißt, jede Frequenz, die im Spektrum des abgeschnitten Signal aufgetreten ist, ist auch im Spektrum aller Fenster aufgetreten, aber diese Frequenzen kommen nicht so häufig wie im originalen Signal vor, weil außerhalb der Fenster sind die Amplituden von Signal 0(manche Frequenzen kommen gar nicht vor).


%
% CHAPTER Versuch 2
%
\chapter{Spracherkennung}
\section{Fragestellung, Messprinzip, Aufbau, Messmittel}
\qquad Die vier Befehle "Hoch", "Tief", "Links$"$ und "Rechts" werden jeweils 5 Mal von gleichem Sprecher aufgenommen und mit der Windowing-Methode von vorherigem Versuch deren Spektren berechnen. Durch die Mittelung dieser Spektren ergibt sich die Referenzspektren von den 4 Befehlen. Die Referenzspektren werden für den Spracherkenner benötigt, indem wir die Berechnung der Korrelationskoeffizienten nach Bravais-Pearson zum Vergleich zweier Spektren(Referenzspektrum und Eingabespektrum) durchführen. Beim Vergleich identischer Spektren sollte die Korrelation 1 sein, bei verschiedenen Spektren nahe an 0. 

Beim Spracherkenner werden Korrelationskoeffizient von dem Eingabespektrum mit jedem Referenzspektrum berechnet. Dann werden die Korrelationskoeffizienten miteinander verglichen. Das Wort hat die Korrelationskoeffizient, die am meisten in der Nähe von 1 liegt, wird ausgewählt.

Zum Testen des Spracherkenners werden die oben genannten Befehle jeweils noch 5 Mal von 2 Sprechern aufgenommen. Die Detektions- und die Fehlerrate wird notiert.

\section{Messwerte}
\label{chap:VERSUCH_2_MESSWERTE}
\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{spektrum_mittel_windowshoch.png}
	\caption{Referenzspektrum von dem Befehl "Hoch"}
\end{figure}

\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{spektrum_mittel_windowstief.png}
	\caption{Referenzspektrum von dem Befehl "Tief"}
\end{figure}

\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{spektrum_mittel_windowsrechts.png}
	\caption{Referenzspektrum von dem Befehl "Rechts"}
\end{figure}

\begin{figure}[H]
	\centering\small
	\includegraphics[width=12cm]{spektrum_mittel_windowslinks.png}
	\caption{Referenzspektrum von dem Befehl "Links"}
\end{figure}
\section{Auswertung}

\label{chap:VERSUCH_2_AUSWERTUNG}

\textit{Korrelationskoeffizient nach Bravais-Pearson:} $$r_{fg}=\frac{\sigma_{fg}}{\sigma_{f}\cdot\sigma_{g}}$$ indem $\sigma_{f}$ und $\sigma_{g}$ jeweils Standardabweichungen von den entsprechenden Signalen f und g sind, die nach der Formel berechnet: $$\sigma^2_f=\frac{1}{n-1}\sum_{k=1}^{n}(f_k-\mu_f)^2$$
\qquad\textit{Die Kovarianz} $\sigma_{fg}$ ist für diskrete Signale definiert als:$$\sigma_{fg}=\frac{1}{n}\sum_{k=1}^{n}(f_k-\mu_f)\cdot(g_k-\mu_g)$$
\qquad $\mu_f$ ist \textit{der Mittelwert:} $$\mu_f=\frac{1}{n}\sum_{k=1}^nf_k$$

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{1}{|c|}{Befehl} & \multicolumn{1}{c|}{Sprecher 1}		& \multicolumn{1}{c|}{Sprecher 2}			\\ \hline
Hoch						&$100\%$				&$100\%$				\\ \hline
Tief						&$100\%$				&$80\%$					\\ \hline
Links						&$100\%$				&$100\%$				\\ \hline
Rechts						&$100\%$				&$80\%$					\\ \hline
\end{tabular}
\caption{Detektionsrate}
\end{table}



Den Code davon bitte den Anhang A.1.3 und A.1.4 sehen.

\section{Interpretation}
\label{chap:VERSUCH_2_INTERPRETATION}
\qquad Die Detektion besagt, dass beim Sprecher 1 100$\%$ das Wort korrekt erkannt wurde und beim Sprecher 2 ist abweichend bei der Erkennung der Befehle "Tief$"$ und "Rechts". Das ist total verständlich, weil der Sprecher 1 ist die Person, von der die Referenzspektren hergestellt wurden. Bei dem anderen Sprecher wurde die Befehlen manchmal falsch erkannt. Die Erklärung dafür ist aus den anatomischen Gründe, dass jede Person eigene Stimme und eigene Sprechweise(Akzent) hat. Die Fehlerrate ist nicht so hoch, da die Datenbank der Referenzspektrum noch ziemlich klein ist (von nur 4 Befehlen).

%
% CHAPTER Anhang
%
\renewcommand\thesection{A.\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}

\chapter*{Anhang}
\label{chap:APPENDIX}
\addcontentsline{toc}{chapter}{Anhang}
%\setcounter{chapter}{0}
\addtocounter{chapter}{1}
\setcounter{section}{0}

\section{Quellcode}
\label{chap:APPENDIX_SOURCECODE}

\subsection{Quellcode Signal Aufnehmen, Triggerfunktion und Fourriertransformation}
\label{chap:APPENDIX_SOURCECODE_V1}
\begin{lstlisting}[
style=PYTHON,
frame=single,
caption=,
captionpos=b,
label=lst:V1]
import pyaudio 
import numpy as np
import matplotlib.pyplot as plt

FORMAT = pyaudio.paInt16
SAMPLEFREQ = 44100
FRAMESIZE = 1024
NOFFRAMES = 220
INPUT_BLOCK_TIME = 0.05 
INPUT_FRAMES_PER_BLOCK = int(SAMPLEFREQ*INPUT_BLOCK_TIME)
p = pyaudio.PyAudio()
print('running')
stream = p.open(format=FORMAT,channels=1,rate=SAMPLEFREQ, input=True,frames_per_buffer=FRAMESIZE)
data = stream.read(NOFFRAMES*FRAMESIZE) 
decoded = np.fromstring(data, 'Int16')
stream.stop_stream() 
stream.close() 
p.terminate() 
print('done') 

#######Signal speichern und darstellen########
string = 'hoch1'
np.save(string,decoded)
sec = len(decoded) / SAMPLEFREQ
plt.xlabel('Zeit in s')
plt.ylabel('Amplitude')
Zeit = []
for i in range (len(decoded)):
    Zeit.append(sec/len(decoded) * i)
plt.plot(Zeit,decoded) 
plt.show()

####Signal mit Triggerfunktion abschneiden####
trigger = 0.1 * np.max(decoded)
j = 0
for i in decoded:
    j = j + 1
    if np.abs(i) > trigger:
        decoded = decoded[j:j+SAMPLEFREQ]
        break
np.save(string+'abgeschnitten',decoded)
plt.xlabel('Zeit in s')
plt.ylabel('Amplitude')
Zeit = []
for i in range (len(decoded)):
    Zeit.append(1/len(decoded) * i)
plt.plot(Zeit,decoded) 
plt.show()

###########Fourriertranformation###############
spek = abs(np.fft.fft(decoded))
plt.plot(spek)
plt.savefig('Amplitudenspektrum.png')
\end{lstlisting}

\subsection{Quellcode Windowing und Spektrum Versuch 1}
\label{chap:APPENDIX_SOURCECODE_V1}
\begin{lstlisting}[
style=PYTHON,
frame=single,
caption=,
captionpos=b,
label=lst:V2]
import numpy as np
import matplotlib.pyplot as plt

def fft(data,name):
    plt.figure(figsize=(9,6))
    Y = abs(np.fft.fft(data))
    Y = Y[range(int(len(Y)/2))]
    x = np.linspace(0,22050,22050,endpoint = True)
    plt.xlabel('Frequenz($Hertz$)')
    plt.ylabel('Amplitude($Unit$)')
    plt.plot(x,abs(Y))
    plt.savefig(str(name)+".png")
    plt.show()
    
def winspek(data,name):
    plt.figure(figsize=(9,6))
    plt.xlabel('Frequenz($Hertz$)')
    plt.ylabel('Amplitude($Unit$)')
    st = np.std(data)
    from scipy import signal
    gfen = signal.gaussian(512, std = st * 4)
    g = np.zeros(len(data))
    fft = np.zeros(len(data))
    x = np.linspace(0,22050,22050,endpoint = True)
    for i in range(0,len(data),256):
        if (i > len(data) - 512):
            gfen = signal.gaussian(len(data)-i, std = st * 4)
            g[i:] = data[i:] * gfen
            fft += abs(np.fft.fft(g))
            a = np.fft.fft(g)
            a = a[range(int(len(a)/2))]
            plt.plot(x,abs(a))
            break
        g[i:i+512] = data[i:i+512] * gfen
        fft += abs(np.fft.fft(g))
        a = np.fft.fft(g)
        a = a[range(int(len(a)/2))]
        plt.plot(x,abs(a))
        g = np.zeros(len(data))
    plt.savefig("spektrum_gesamter_windows"+str(name)+".png")
    plt.show()
    fft /= 171 #durch die Anzahl der Windows teilen
    fft = fft[range(int(len(fft)/2))]
    plt.figure(figsize=(9,6))
    plt.xlabel('Frequenz($Hertz$)')
    plt.ylabel('Amplitude($Unit$)')
    plt.plot(x,fft)
    plt.savefig("spektrum_mittel_windows"+str(name)+".png")
    return fft
    
data = np.load('was_cooles_abgeschnitten.npy')
plt.figure(figsize=(9,6))
plt.xlabel('Zeit in s')
plt.ylabel('Amplitude')
Zeit = []
for i in range (len(data)):
    Zeit.append(1/len(data) * i)
plt.plot(Zeit,data)
plt.savefig("v1_abgeschnitten.png")
plt.show()
fft(data,"Amplitudenspektrum")

winspek(data,"v1")
\end{lstlisting}

\subsection{Quellcode Windowing und Referenzspektrum Versuch 2}
\label{chap:APPENDIX_SOURCECODE_V2}
\begin{lstlisting}[
style=PYTHON,
frame=single,
caption=,
captionpos=b,
label=lst:V2]
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal

def winspek(data):
    st = np.std(data)
    gfen = signal.gaussian(512, std = st * 4)
    g = np.zeros(len(data))
    fft = np.zeros(len(data))
    for i in range(0,len(data),256):
        if (i > len(data) - 512):
            break
        g[i:i+512] = data[i:i+512] * gfen
        fft += abs(np.fft.fft(g))
        a = np.fft.fft(g)
        a = a[range(int(len(a)/2))]
        g = np.zeros(len(data))
    
    fft /= 171 #durch die Anzahl der Windows teilen
    fft = fft[range(int(len(fft)/2))]
    return fft

data = np.load('hoch1abgeschnitten.npy')
mit =  np.zeros(int(len(data)/2))
a = ['hoch', 'tief', 'rechts', 'links']
for j in a:
    mit = 0
    for i in range(1,6):
        data = np.load(j + str(i) + 'abgeschnitten.npy')
        np.save('spek' + j + str(i),winspek(data))
        mit+=winspek(data)
    mit = mit/5
    np.save('ref' + j,mit)
    plt.figure(figsize=(9,6))
    plt.xlabel('Frequenz($Hertz$)')
    plt.ylabel('Amplitude($Unit$)')
    plt.plot(mit)
    plt.savefig("spektrum_mittel_windows" + j + ".png")
    plt.show()
\end{lstlisting}

\subsection{Quellcode Korrelation und Spracherkenner Versuch 2}
\label{chap:APPENDIX_SOURCECODE_V2}
\begin{lstlisting}[
style=PYTHON,
frame=single,
caption=,
captionpos=b,
label=lst:V2]
import numpy as np

refhoch = np.load('experiment 2a/refhoch.npy')
reftief = np.load('experiment 2a/reftief.npy')
refrechts = np.load('experiment 2a/refrechts.npy')
reflinks = np.load('experiment 2a/reflinks.npy')
def spracherkenner(name,person):
    for i in range(1,6):
        test = np.load('Spek/spek'+str(name)+str(i)+'t'+str(person)+'.npy')
        korrcoefh = np.corrcoef(refhoch, y = test)
        korrcoeft = np.corrcoef(reftief, y = test)
        korrcoefr = np.corrcoef(refrechts, y = test)
        korrcoefl = np.corrcoef(reflinks, y = test)
        a = np.max([np.mean(korrcoefh), np.mean(korrcoeft), np.mean(korrcoefr), np.mean(korrcoefl)])
        if a == np.mean(korrcoefh):
            print('hoch')
        elif a == np.mean(korrcoeft):
            print('tief')
        elif a == np.mean(korrcoefr):
            print('rechts')
        elif a == np.mean(korrcoefl):
            print('links')
            
spracherkenner('links','p')
print("----")
spracherkenner('links','s')
\end{lstlisting}

\end{document}
%------------------------------------
% ╔═╗╔╗╔╔╦╗  ╔╦╗╔═╗╔═╗╦  ╦╔╦╗╔═╗╔╗╔╔╦╗
% ║╣  ║║║  ║║     ║║║  ║║    ║  ║║║║║ ╣  ║║║ ║ 
% ╚═╝╝╚╝═╩╝  ═╩╝╚═╝╚═╝╚═╝╩  ╩╚═╝╝╚╝  ╩ 
%------------------------------------